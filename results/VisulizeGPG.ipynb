{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38644a9-462c-42e2-9cdb-29f38ff6f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "\n",
    "\n",
    "new_dir = '/home/ma/ma_ma/ma_lineuman/Interpretable-Deep-Fake-Detection/results'\n",
    "if os.path.exists(new_dir):\n",
    "    os.chdir(new_dir)\n",
    "    print(\"Changed working directory to:\", os.getcwd())\n",
    "else:\n",
    "    print(\"Directory does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3288f1-0ad7-4b37-a32e-8abd21f908c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save(img_np, heatmap, true_fake_pos, weighted_guessed_fake_position, weighted_localization_score, unweighted_localization_score, unweighted_guessed_fake_position, grid_split, model_prediction, save_folder=\"results\", file_prefix=\"visualization\"):\n",
    "    \"\"\"\n",
    "    Visualisiert das Originalbild und die Heatmap nebeneinander und speichert die Abbildung unter einem eindeutigen Dateinamen.\n",
    "    \"\"\"\n",
    "    print(f\"[DEBUG] Visualizing heatmap with shape: {heatmap.shape}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # --- Linke Seite: Originalbild ---\n",
    "    ax1.imshow(img_np)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    colors = [\"white\", \"red\"]\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"white_to_red\", colors)\n",
    "    \n",
    "    # --- Rechte Seite: Heatmap ---\n",
    "    ax2.imshow(heatmap, cmap=custom_cmap)\n",
    "    ax2.set_title(\"Heatmap\")\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    # Überschrift mit Anmerkungen\n",
    "    fig.suptitle(\n",
    "        f\"True Fake Pos: {true_fake_pos}, weighted Guess: {weighted_guessed_fake_position}, unweighted Guess: {unweighted_guessed_fake_position}\\n\"\n",
    "        f\"Intensity-Weighted Localization Score: {weighted_localization_score:.4f}, Unweighted Localization Score: {unweighted_localization_score:.4f}, Modelprediction: {model_prediction}\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Sicherstellen, dass der Speicherordner existiert.\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    # Eindeutigen Dateinamen generieren: Prefix, echte/erratene Position und ein zufälliger UUID-Teil.\n",
    "    unique_id = uuid.uuid4().hex[:8]\n",
    "    filename = f\"{file_prefix}_{true_fake_pos}_{unweighted_guessed_fake_position}_{unique_id}.png\"\n",
    "    filepath = os.path.join(save_folder, filename)\n",
    "\n",
    "    # Abbildung speichern.\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved visualization to {filepath}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825cc70e-9203-43da-bdee-01fdaa9fedc3",
   "metadata": {},
   "source": [
    "########################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8998e-281b-4b8f-80f9-a62ff4ddd999",
   "metadata": {},
   "source": [
    "Visulize top 10 grid per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f79d2-7023-4d98-85e4-f63399114fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_file = os.path.join(\"/pfs/work9/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/resultsGPG\",\"resnet34_test_res_gradcam_config\",\"3x3\",\"results_by_threshold.pkl\")\n",
    "print(\"Results file path:\", os.path.abspath(results_file))\n",
    "\n",
    "with open(results_file, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# 2) pick out only the threshold==0 entries\n",
    "#    (we saved threshold=None as 0 in the dict keys)\n",
    "threshold0 = results.get(0, [])\n",
    "\n",
    "# 3) sort by unweighted localization score and take top 10\n",
    "top10 = sorted(\n",
    "    threshold0,\n",
    "    key=lambda r: r.get(\"weighted_localization_score\", 0),\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "grid_split = 3  # your grid size\n",
    "\n",
    "# 4) visualize\n",
    "for rank, best in enumerate(top10, 1):\n",
    "    img_np   = best[\"original_image\"]\n",
    "    heatmap  = best[\"heatmap\"]\n",
    "    true_fp  = best[\"true_fake_position\"]\n",
    "    wg_fp    = best[\"weighted_guessed_fake_position\"]\n",
    "    wg_score = best[\"weighted_localization_score\"]\n",
    "    uw_score = best[\"unweighted_localization_score\"]\n",
    "    uw_fp    = best[\"unweighted_guess_fake_position\"]\n",
    "    pred     = best[\"model_prediction\"]\n",
    "    # threshold is always 0 here\n",
    "\n",
    "    print(f\"{rank}. wg_score={wg_score:.3f}, true={true_fp}, wg_guess={wg_fp}\")\n",
    "\n",
    "    visualize_and_save(\n",
    "        img_np,\n",
    "        heatmap,\n",
    "        true_fp,\n",
    "        wg_fp,\n",
    "        wg_score,\n",
    "        uw_score,\n",
    "        uw_fp,\n",
    "        grid_split,\n",
    "        pred,\n",
    "        save_folder=\"results/top10_thresh0\",\n",
    "        file_prefix=f\"#{rank}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e8ae0-02ff-44db-9909-7ba73b4e28b2",
   "metadata": {},
   "source": [
    "###################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa6c9c-f808-4d5b-9f7d-06bd2c54b78d",
   "metadata": {},
   "source": [
    "Visulize all Grids !!!!!Warning!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd916f-3248-4eee-b7fd-7ec07868cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "for threshold, result_list in results.items():\n",
    "    for result in result_list:\n",
    "        path = result.get(\"path\")\n",
    "        img_np = result.get(\"original_image\")\n",
    "        heatmap = result.get(\"heatmap\")\n",
    "        true_fake_pos = result.get(\"true_fake_position\")\n",
    "        weighted_guessed_fake_position = result.get(\"weighted_guessed_fake_position\")\n",
    "        unweighted_guess_fake_position = result.get(\"unweighted_guess_fake_position\")\n",
    "        model_prediction = result.get(\"model_prediction\")\n",
    "        weighted_localization_score = result.get(\"weighted_localization_score\", 0.0)\n",
    "        unweighted_localization_score = result.get(\"unweighted_localization_score\", 0.0)\n",
    "\n",
    "        grid_split = 3  # oder 4 oder was auch immer du verwendet hast\n",
    "        print(f\"[DEBUG] img_np shape after transpose: {img_np.shape}, dtype: {img_np.dtype}, max: {img_np.max()}\")\n",
    "\n",
    "\n",
    "        \n",
    "        print(f\"Threshold {threshold} | Weighted localization score: {weighted_localization_score:.2f} | weighted Guessed: {weighted_guessed_fake_position} | True: {true_fake_pos}\")\n",
    "        visualize_and_save(img_np, heatmap, true_fake_pos, weighted_guessed_fake_position, weighted_localization_score, unweighted_localization_score, unweighted_guess_fake_position, grid_split, model_prediction, save_folder=\"results\", file_prefix=\"visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbc093-8eea-4028-b9f3-f59654badbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────────────────────\n",
    "# point this to your actual grids folder:\n",
    "grid_dir = \"resnet34_default/3x3\"\n",
    "\n",
    "# which grid to display? 0‐based index into sorted list of .pt files\n",
    "grid_index = 0\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "# find all the .pt files\n",
    "grid_paths = sorted(glob.glob(os.path.join(grid_dir, \"*.pt\")))\n",
    "if not grid_paths:\n",
    "    raise FileNotFoundError(f\"No .pt files found in {grid_dir!r}\")\n",
    "\n",
    "path = grid_paths[grid_index]\n",
    "print(\"Showing grid:\", os.path.basename(path))\n",
    "\n",
    "# load the tensor\n",
    "grid_tensor = torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "# remove any leading batch‐dim\n",
    "# expected shape now: [C, H, W]\n",
    "if grid_tensor.ndim == 4 and grid_tensor.size(0) == 1:\n",
    "    grid_tensor = grid_tensor.squeeze(0)\n",
    "elif grid_tensor.ndim not in (3,):\n",
    "    raise ValueError(f\"Unexpected tensor shape {tuple(grid_tensor.shape)}\")\n",
    "\n",
    "#if it has >3 channels (BCoS gives 6), keep only RGB\n",
    "#if grid_tensor.size(0) > 3:\n",
    "    #img = grid_tensor[:3]\n",
    "#else:\n",
    "img = grid_tensor\n",
    "\n",
    "# move to HWC and numpy\n",
    "img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# normalize to [0,1] for display\n",
    "img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(os.path.basename(path))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf485cc-4bf3-42bb-afad-23cccb8641d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "for threshold, result_list in results.items():\n",
    "    for result in result_list:\n",
    "        path = result.get(\"path\")\n",
    "        img_np = result.get(\"original_image\")\n",
    "        heatmap = result.get(\"heatmap\")\n",
    "        true_fake_pos = result.get(\"true_fake_position\")\n",
    "        guessed_fake_pos = result.get(\"guessed_fake_position\")\n",
    "        model_prediction = result.get(\"model_prediction\")\n",
    "        accuracy = result.get(\"accuracy\", 0.0)\n",
    "\n",
    "        grid_split = 3  # oder 4 oder was auch immer du verwendet hast\n",
    "\n",
    "        print(f\"Threshold {threshold} | Accuracy: {accuracy:.2f} | Guessed: {guessed_fake_pos} | True: {true_fake_pos}\")\n",
    "        visualize_and_save(img_np, heatmap, true_fake_pos, guessed_fake_pos, accuracy, grid_split, model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952de8f-5860-493a-8f14-642ecf428048",
   "metadata": {},
   "source": [
    "################################################################################################################################################################################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5f29f-8a29-43be-80af-dad45afeabdf",
   "metadata": {},
   "source": [
    "Visulization of mean accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e229900-2dac-416b-8dec-2a6bfa0cd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ─────────── CONFIG ───────────\n",
    "models = [\n",
    "    \"resnet34_bcos_v2_test_bcos_res_2_5_config\",\n",
    "    \"resnet34_test_res_xgrad_config\",\n",
    "    \"resnet34_bcos_v2_test_bcos_res_1_25_config\",\n",
    "    \"resnet34_test_res_lime_config\",\n",
    "    \"resnet34_test_res_layergrad_config\",\n",
    "    \"resnet34_test_res_grad++_config\",\n",
    "    \"resnet34_test_res_gradcam_config\",\n",
    "    # ggf. weitere Modelle hier\n",
    "]\n",
    "results_base = \"/pfs/work9/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/resultsGPG\"\n",
    "grid_subpath  = \"3x3\"\n",
    "threshold_key = 0.5  # unser „no threshold“, wird im Dict als 0 gespeichert\n",
    "# ───────────────────────────────\n",
    "\n",
    "print(\"| Model                                           | Weighted avg | Unweighted avg |\")\n",
    "print(\"|:------------------------------------------------|------------:|---------------:|\")\n",
    "\n",
    "for m in models:\n",
    "    pkl = os.path.join(results_base, m, grid_subpath, \"results_by_threshold.pkl\")\n",
    "    with open(pkl, \"rb\") as f:\n",
    "        res = pickle.load(f)\n",
    "    entries = res.get(threshold_key, [])\n",
    "    if not entries:\n",
    "        print(f\"| {m:48} |      n/a    |       n/a     |\")\n",
    "        continue\n",
    "\n",
    "    w_scores = [e[\"weighted_localization_score\"]   for e in entries]\n",
    "    u_scores = [e[\"unweighted_localization_score\"] for e in entries]\n",
    "    w_mean = np.mean(w_scores)\n",
    "    u_mean = np.mean(u_scores)\n",
    "\n",
    "    print(f\"| {m:48} | {w_mean:12.4f} | {u_mean:14.4f} |\")\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73eabce-dd48-4360-8228-e38f9f120ff3",
   "metadata": {},
   "source": [
    "Graph Weighted localization score x treshhold (each on own data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67160668-2949-4012-9a71-f02f15cd2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─────────── CONFIG ───────────\n",
    "models = [\n",
    "    \"resnet34_bcos_v2_test_bcos_res_1_25_config\",\n",
    "    #\"resnet34_bcos_v2_test_bcos_res_1_75_config\",\n",
    "    #\"resnet34_bcos_v2_test_bcos_res_2_config\",\n",
    "    \"resnet34_bcos_v2_test_bcos_res_2_5_config\",\n",
    "    \"resnet34_test_res_lime_config\",\n",
    "    \"resnet34_test_res_xgrad_config\",\n",
    "    \"resnet34_test_res_layergrad_config\",\n",
    "    \"resnet34_test_res_grad++_config\",\n",
    "    \"resnet34_test_res_gradcam_config\",\n",
    "    # ggf. weitere Modelle hier\n",
    "]\n",
    "results_base = \"/pfs/work9/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/resultsGPG\"\n",
    "grid_subpath  = \"3x3\"\n",
    "fname         = \"results_by_threshold.pkl\"\n",
    "# ─────────────────────────────────────────\n",
    "\n",
    "def parse_folder_name(folder: str):\n",
    "    \"\"\"\n",
    "    Aus 'resnet34_test_res_gradcam_config' → ('resnet34', 'gradcam')\n",
    "    \"\"\"\n",
    "    assert folder.endswith(\"_config\"), f\"Erwarte Ordnername auf '_config' endend, got {folder}\"\n",
    "    core = folder[:-len(\"_config\")]               # 'resnet34_bcos_v2_test_bcos_res_2_5'\n",
    "    model, rest = core.split(\"_test_\", 1)          # ['resnet34_bcos_v2', 'bcos_res_2_5']\n",
    "    xai = rest.split(\"res_\")[1:]\n",
    "    return model, xai\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for model_name in models:\n",
    "    model, xai = parse_folder_name(model_name)\n",
    "    label = f\"{model} ({xai[0]})\"\n",
    "    pkl_path = os.path.join(results_base, model_name, grid_subpath, fname)\n",
    "    if not os.path.isfile(pkl_path):\n",
    "        print(f\"⚠️ missing {pkl_path}\")\n",
    "        continue\n",
    "\n",
    "    # load grouped-by-threshold dict: { threshold: [entry, ...], ... }\n",
    "    with open(pkl_path,'rb') as f:\n",
    "        by_thr = pickle.load(f)\n",
    "\n",
    "    # sort thresholds numerically\n",
    "    threshs = sorted(by_thr.keys())\n",
    "    mean_weighted = []\n",
    "    #mean_unweighted = []\n",
    "\n",
    "    for t in threshs:\n",
    "        entries = by_thr[t]\n",
    "        if not entries:\n",
    "            mean_weighted.append(np.nan)\n",
    "            #mean_unweighted.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        w = [e[\"weighted_localization_score\"]   for e in entries]\n",
    "        #u = [e[\"unweighted_localization_score\"] for e in entries]\n",
    "        mean_weighted.append(np.mean(w))\n",
    "        #mean_unweighted.append(np.mean(u))\n",
    "\n",
    "    plt.plot(threshs, mean_weighted, marker='o', label=label)\n",
    "    #plt.plot(threshs, mean_unweighted, linestyle='--', marker='x', label=model_name+\" (unw.)\")\n",
    "\n",
    "plt.xticks(threshs)                       # Ticks bei 0.0,0.1,...,1.0\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Mean weighted localization score\")\n",
    "plt.title(\"Per-model performance vs. threshold\")\n",
    "#plt.legend(loc=\"best\", fontsize=\"small\")\n",
    "plt.legend(\n",
    "    loc=\"upper center\",              # Position relativ zum bbox_to_anchor\n",
    "    bbox_to_anchor=(0.5, -0.15),     # (x, y) – x=0.5 Mitte, y<0 unterhalb der Achse\n",
    "    ncol=4,                          # Anzahl Spalten in der Legende (anpassen!)\n",
    "    fontsize=\"small\",\n",
    "    frameon=False\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662c6da-a315-406e-8b0b-2f92fef8ca31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b65379-dad7-4b23-9f82-8e30bd027d8c",
   "metadata": {},
   "source": [
    "Graph Weighted localization score x treshhold (each on pooled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20555f91-c3c4-45f9-b91d-30ac9448b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─────────── CONFIG ───────────\n",
    "models = [\n",
    "    \"resnet34_bcos_v2_test_bcos_res_1_25_config\",\n",
    "    #\"resnet34_bcos_v2_test_bcos_res_1_75_config\",\n",
    "    #\"resnet34_bcos_v2_test_bcos_res_2_config\",\n",
    "    \"resnet34_bcos_v2_test_bcos_res_2_5_config\",\n",
    "    \"resnet34_test_res_lime_config\",\n",
    "    \"resnet34_test_res_xgrad_config\",\n",
    "    \"resnet34_test_res_layergrad_config\",\n",
    "    \"resnet34_test_res_grad++_config\",\n",
    "    \"resnet34_test_res_gradcam_config\",\n",
    "    # ggf. weitere Modelle hier\n",
    "]\n",
    "results_base = \"/pfs/work9/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/resultsGPG\"\n",
    "grid_subpath  = \"3x3\"\n",
    "fname         = \"results_by_threshold.pkl\"\n",
    "# ─────────────────────────────────────────\n",
    "\n",
    "def parse_folder_name(folder: str):\n",
    "    \"\"\"\n",
    "    Aus 'resnet34_test_res_gradcam_config' → ('resnet34', 'gradcam')\n",
    "    \"\"\"\n",
    "    assert folder.endswith(\"_config\"), f\"Erwarte Ordnername auf '_config' endend, got {folder}\"\n",
    "    core = folder[:-len(\"_config\")]               # 'resnet34_bcos_v2_test_bcos_res_2_5'\n",
    "    model, rest = core.split(\"_test_\", 1)          # ['resnet34_bcos_v2', 'bcos_res_2_5']\n",
    "    xai = rest.split(\"res_\")[1:]\n",
    "    return model, xai\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for model_name in models:\n",
    "    model, xai = parse_folder_name(model_name)\n",
    "    label = f\"{model} ({xai[0]})\"\n",
    "    pkl_path = os.path.join(results_base, model_name, grid_subpath, fname)\n",
    "    if not os.path.isfile(pkl_path):\n",
    "        print(f\"⚠️ missing {pkl_path}\")\n",
    "        continue\n",
    "\n",
    "    # load grouped-by-threshold dict: { threshold: [entry, ...], ... }\n",
    "    with open(pkl_path,'rb') as f:\n",
    "        by_thr = pickle.load(f)\n",
    "\n",
    "    # sort thresholds numerically\n",
    "    threshs = sorted(by_thr.keys())\n",
    "    mean_weighted = []\n",
    "    #mean_unweighted = []\n",
    "\n",
    "    for t in threshs:\n",
    "        entries = by_thr[t]\n",
    "        if not entries:\n",
    "            mean_weighted.append(np.nan)\n",
    "            #mean_unweighted.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        w = [e[\"weighted_localization_score\"]   for e in entries]\n",
    "        #u = [e[\"unweighted_localization_score\"] for e in entries]\n",
    "        mean_weighted.append(np.mean(w))\n",
    "        #mean_unweighted.append(np.mean(u))\n",
    "\n",
    "    plt.plot(threshs, mean_weighted, marker='o', label=label)\n",
    "    #plt.plot(threshs, mean_unweighted, linestyle='--', marker='x', label=model_name+\" (unw.)\")\n",
    "\n",
    "plt.xticks(threshs)                       # Ticks bei 0.0,0.1,...,1.0\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Mean weighted localization score\")\n",
    "plt.title(\"Per-model performance vs. threshold\")\n",
    "#plt.legend(loc=\"best\", fontsize=\"small\")\n",
    "plt.legend(\n",
    "    loc=\"upper center\",              # Position relativ zum bbox_to_anchor\n",
    "    bbox_to_anchor=(0.5, -0.15),     # (x, y) – x=0.5 Mitte, y<0 unterhalb der Achse\n",
    "    ncol=4,                          # Anzahl Spalten in der Legende (anpassen!)\n",
    "    fontsize=\"small\",\n",
    "    frameon=False\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
