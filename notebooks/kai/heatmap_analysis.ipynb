{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e062d6-d3de-4681-85a8-6f7ecade7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.set_device(0)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6462515-38a0-4153-98f7-113b2fcc0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" \n",
    "sys.argv = [\"train.py\"]\n",
    "from train import init_seed, prepare_training_data, prepare_testing_data, choose_optimizer, choose_scheduler, choose_metric\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from datetime import timedelta\n",
    "from detectors import DETECTOR\n",
    "# from trainer.trainer import Trainer\n",
    "pretrained_paths = ['/pfs/work7/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/weights/resnet34_v2_minimal/03_10_16_34_15_ckpt_best.pth',\n",
    "                   '/pfs/work7/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/weights/bcos_resnet_minimal_b2_ckpt_best.pth']\n",
    "path = \"./config/detector/resnet34_bcos_v2_minimal.yaml\"\n",
    "additional_args = {'test_batchSize': 4,\n",
    "                  'pretrained': pretrained_paths[1],\n",
    "                  'backbone_config':{'b': 2}\n",
    "                  }\n",
    "config = load_config(path, additional_args=additional_args)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcaf4f-c1c9-4279-ac1f-51e98c7a9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ff3b5-95ff-4c9a-b7bd-625f6a963979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(34)\n",
    "random.seed(34)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "for path in pretrained_paths:\n",
    "    state_dict = torch.load(path)\n",
    "    # Remove \"module.\" prefix\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "        new_state_dict[new_key] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.cuda()#.to(\"cuda:0\")\n",
    "    print(next(model.parameters()).device)\n",
    "    \n",
    "    model.eval()\n",
    "    # testing for all test data\n",
    "    keys = test_data_loaders.keys()\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        data_dict = test_data_loaders[key].dataset.data_dict\n",
    "        for i, data_dict in tqdm(enumerate(test_data_loaders[key]),total=len(test_data_loaders[key])):\n",
    "            if i < 3:\n",
    "                if 'label_spe' in data_dict:\n",
    "                    data_dict.pop('label_spe')  # remove the specific label\n",
    "                data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "                # move data to GPU elegantly\n",
    "                for key in data_dict.keys():\n",
    "                    if data_dict[key]!=None:\n",
    "                        data_dict[key]=data_dict[key].cuda()\n",
    "                # model forward without considering gradient computation\n",
    "                # print(data_dict)\n",
    "                with torch.no_grad():\n",
    "                    predictions = inference(model, data_dict)\n",
    "                print(data_dict['label'])\n",
    "                print(predictions['prob'])\n",
    "            else:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f2eff-3c47-4edb-972a-c75206f70e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bcos.interpretability import grad_to_img, to_numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "random.seed(2)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# prepare the training data loader\n",
    "# train_data_loader = prepare_training_data(config)\n",
    "config['test_batchSize'] = 2\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "for path in pretrained_paths:\n",
    "    state_dict = torch.load(path)\n",
    "    # Remove \"module.\" prefix\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "        new_state_dict[new_key] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.to(device)#.cuda()\n",
    "    print(next(model.parameters()).device)\n",
    "    # testing for all test data\n",
    "    key = list(test_data_loaders.keys())[0]\n",
    "    print(key)\n",
    "    for i, data_dict in enumerate(test_data_loaders[key]):#img_batch, label_batch in dataloader:\n",
    "        if i<3:\n",
    "            print(data_dict.keys())\n",
    "            img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "            print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "            # device = \"cpu\"\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "            num_batches = img_batch.shape[0]\n",
    "            # Iterate through each image in the batch\n",
    "            for i in range(num_batches):\n",
    "                img = img_batch[i].unsqueeze(0).to(device)#).cuda()  # Process a single image\n",
    "                label = label_batch[i]\n",
    "        \n",
    "                # img = img.requires_grad_(True)\n",
    "\n",
    "                # input_tensor = img.clone().requires_grad_()\n",
    "\n",
    "                # # 1. Enter explanation mode\n",
    "                # with model.backbone.explanation_mode():\n",
    "                #     # 2. do a fwd pass\n",
    "                #     out = model.backbone(input_tensor)\n",
    "                \n",
    "                #     # 3. bwd pass on prediction logit wrt input\n",
    "                #     prediction_logit = out.max(1).values\n",
    "                #     prediction_logit.backward(inputs=[input_tensor])\n",
    "                \n",
    "                \n",
    "                # dynamic_linear_weights = input_tensor.grad\n",
    "                model.backbone.eval()\n",
    "                explanation = model.backbone.explain(img)\n",
    "                print(explanation.keys())\n",
    "                print(explanation['prediction'])\n",
    "                # plt.imshow(explanation)\n",
    "                # plt.imshow(explanation['explanation'])\n",
    "                #plt.imshow(att, extent=(config['resolution'], 2 * config['resolution'], 0, config['resolution']))\n",
    "                # 2. Create the figure with two subplots side by side\n",
    "                img_np = np.array(to_numpy(img[0, [0, 1, 2]].permute(1, 2, 0)) * 255, dtype=np.uint8)\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "                \n",
    "                # 3. Plot the original image on the left subplot\n",
    "                axes[0].imshow(img_np, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "                axes[0].set_title(f\"Original Image - Label {label}\")\n",
    "                axes[0].set_xlim(0, config['resolution'])\n",
    "                axes[0].set_xticks([])\n",
    "                axes[0].set_yticks([])\n",
    "                for spine in axes[0].spines.values():\n",
    "                    spine.set_visible(False)\n",
    "                \n",
    "                # 4. Plot the explanation (or any relevant data) on the right subplot\n",
    "                # Assuming explanation is a tensor or numpy array that you want to visualize\n",
    "                # You can either directly plot the explanation or use another variable such as attention maps or gradients\n",
    "                axes[1].imshow(explanation['explanation'], extent=(0, config['resolution'], 0, config['resolution']))  # Replace explanation with your actual variable\n",
    "                axes[1].set_title(f\"Explained class idx {explanation['explained_class_idx']} - Prediction: {explanation['prediction']} - \")\n",
    "                axes[1].set_xlim(0, config['resolution'])\n",
    "                axes[1].set_xticks([])\n",
    "                axes[1].set_yticks([])\n",
    "                for spine in axes[1].spines.values():\n",
    "                    spine.set_visible(False)\n",
    "                \n",
    "                # 5. Display the plot\n",
    "                plt.tight_layout()  # Ensures proper spacing between plots\n",
    "                plt.show()\n",
    "                \n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e310de-52c6-48eb-9fd4-fe8461d72380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bcos.interpretability import grad_to_img, to_numpy\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "# from tqdm import tqdm\n",
    "# import random\n",
    "# # init seed\n",
    "# # init_seed(config)\n",
    "\n",
    "# torch.manual_seed(2)\n",
    "# random.seed(2)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# # prepare the training data loader\n",
    "# # train_data_loader = prepare_training_data(config)\n",
    "# config['test_batchSize'] = 2\n",
    "# # prepare the testing data loader\n",
    "# train_data_loader = prepare_training_data(config)\n",
    "\n",
    "# # prepare the model (detector)\n",
    "# model_class = DETECTOR[config['model_name']]\n",
    "# model = model_class(config)\n",
    "# for path in pretrained_paths:\n",
    "#     state_dict = torch.load(path)\n",
    "#     # Remove \"module.\" prefix\n",
    "#     from collections import OrderedDict\n",
    "#     new_state_dict = OrderedDict()\n",
    "#     for k, v in state_dict.items():\n",
    "#         new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "#         new_state_dict[new_key] = v\n",
    "    \n",
    "#     model.load_state_dict(new_state_dict)\n",
    "#     model.to(device)#.cuda()\n",
    "#     print(next(model.parameters()).device)\n",
    "#     # testing for all test data\n",
    "#     # key = list(train_data_loaders.keys())[0]\n",
    "#     # print(key)\n",
    "#     for i, data_dict in enumerate(train_data_loader):#img_batch, label_batch in dataloader:\n",
    "#         if i<6:\n",
    "#             print(data_dict.keys())\n",
    "#             img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "#             print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "#             # device = \"cpu\"\n",
    "#             if 'label_spe' in data_dict:\n",
    "#                 data_dict.pop('label_spe')  # remove the specific label\n",
    "#             data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "#             print(data_dict.keys())\n",
    "#             print(data_dict['landmark'])\n",
    "#             # move data to GPU elegantly\n",
    "#             for key in data_dict.keys():\n",
    "#                 if data_dict[key]!=None:\n",
    "#                     data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "#             num_batches = img_batch.shape[0]\n",
    "#             # Iterate through each image in the batch\n",
    "#             for i in range(num_batches):\n",
    "#                 img = img_batch[i].unsqueeze(0).to(device)#).cuda()  # Process a single image\n",
    "#                 label = label_batch[i]\n",
    "#                 # plt.imshow(explanation)\n",
    "#                 # plt.imshow(explanation['explanation'])\n",
    "#                 #plt.imshow(att, extent=(config['resolution'], 2 * config['resolution'], 0, config['resolution']))\n",
    "#                 # 2. Create the figure with two subplots side by side\n",
    "#                 img_np = np.array(to_numpy(img[0, [0, 1, 2]].permute(1, 2, 0)) * 255, dtype=np.uint8)\n",
    "\n",
    "#                 fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "                \n",
    "#                 # 3. Plot the original image on the left subplot\n",
    "#                 axes[0].imshow(img_np, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "#                 axes[0].set_title(f\"Original Image - Label {label}\")\n",
    "#                 axes[0].set_xlim(0, config['resolution'])\n",
    "#                 axes[0].set_xticks([])\n",
    "#                 axes[0].set_yticks([])\n",
    "#                 for spine in axes[0].spines.values():\n",
    "#                     spine.set_visible(False)\n",
    "                \n",
    "#                 # 4. Plot the explanation (or any relevant data) on the right subplot\n",
    "#                 # Assuming explanation is a tensor or numpy array that you want to visualize\n",
    "#                 # You can either directly plot the explanation or use another variable such as attention maps or gradients\n",
    "#                 axes[1].imshow(explanation['explanation'], extent=(0, config['resolution'], 0, config['resolution']))  # Replace explanation with your actual variable\n",
    "#                 axes[1].set_title(f\"Explained class idx {explanation['explained_class_idx']} - Prediction: {explanation['prediction']} - \")\n",
    "#                 axes[1].set_xlim(0, config['resolution'])\n",
    "#                 axes[1].set_xticks([])\n",
    "#                 axes[1].set_yticks([])\n",
    "#                 for spine in axes[1].spines.values():\n",
    "#                     spine.set_visible(False)\n",
    "                \n",
    "#                 # 5. Display the plot\n",
    "#                 plt.tight_layout()  # Ensures proper spacing between plots\n",
    "#                 plt.show()\n",
    "                \n",
    "#         else:\n",
    "#             break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
