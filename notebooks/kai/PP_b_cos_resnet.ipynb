{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) devel/cuda/11.8 => devel/cuda/12.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module load devel/cuda/12.4\n",
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config\n",
    "import os\n",
    "# print(os.getcwd())\n",
    "os.chdir('/pfs/data5/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/training')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 18:37:26.364226: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-04 18:37:26.414027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-04 18:37:26.414070: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-04 18:37:26.414093: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-04 18:37:26.422418: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-04 18:37:27.957073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/pfs/data5/home/ma/ma_ma/ma_kreffert/Jupyter/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.set_device(0)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" \n",
    "sys.argv = [\"train.py\"]\n",
    "from train import init_seed, prepare_training_data, prepare_testing_data, choose_optimizer, choose_scheduler, choose_metric\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from datetime import timedelta\n",
    "from detectors import DETECTOR\n",
    "# from trainer.trainer import Trainer\n",
    "\n",
    "base_path = '/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/logs/training/'\n",
    "pretrained_paths = ['resnet34_bcos_v2_minimal_2025-03-03-20-04-42/test/avg/ckpt_best.pth',\n",
    "                    'resnet34_bcos_v2_minimal_2025-03-03-16-08-52/test/avg/ckpt_best.pth',\n",
    "                    'resnet34_bcos_v2_minimal_2025-03-03-15-05-37/test/avg/ckpt_best.pth',\n",
    "                    'resnet34_bcos_v2_minimal_2025-03-03-14-18-59/test/avg/ckpt_best.pth',\n",
    "                    'resnet34_bcos_v2_minimal_2025-03-03-14-00-05/test/avg/ckpt_best.pth'\n",
    "                   ]\n",
    "pretrained_paths = [f'{base_path}{pretrained_path}' for pretrained_path in pretrained_paths]\n",
    "path = \"./config/detector/resnet34_bcos_v2_minimal.yaml\"\n",
    "additional_args = {'test_batchSize': 4,\n",
    "                  'pretrained': pretrained_paths[0]}\n",
    "config = load_config(path, additional_args=additional_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "FaceForensics++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5586 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5586 [00:07<4:50:52,  3.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7749, 0.5005, 0.6887, 0.8450], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.7421, 0.6160, 0.9278, 0.9470], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5586 [00:07<3:57:24,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8386, 0.9184, 0.6259, 0.7053], device='cuda:0')\n",
      "cuda:0\n",
      "FaceForensics++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5586 [00:00<10:08,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0.8344, 0.6653, 0.7901, 0.8536], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8054, 0.6865, 0.8877, 0.8609], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8401, 0.9084, 0.6597, 0.8135], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "FaceForensics++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5586 [00:00<10:06,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0.8289, 0.6473, 0.7838, 0.8508], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8066, 0.6786, 0.8791, 0.8612], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8348, 0.9079, 0.6454, 0.8027], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "FaceForensics++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5586 [00:00<18:25,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0.8400, 0.7242, 0.8006, 0.8611], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8533, 0.7098, 0.8778, 0.8425], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8548, 0.9085, 0.6962, 0.8236], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "FaceForensics++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5586 [00:00<09:54,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0.7881, 0.4953, 0.6724, 0.8533], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.7623, 0.5628, 0.9402, 0.9453], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.8210, 0.9239, 0.6069, 0.7048], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(34)\n",
    "random.seed(34)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "for path in pretrained_paths:\n",
    "    state_dict = torch.load(path)\n",
    "    # Remove \"module.\" prefix\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "        new_state_dict[new_key] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.cuda()#.to(\"cuda:0\")\n",
    "    print(next(model.parameters()).device)\n",
    "    \n",
    "    model.eval()\n",
    "    # testing for all test data\n",
    "    keys = test_data_loaders.keys()\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        data_dict = test_data_loaders[key].dataset.data_dict\n",
    "        for i, data_dict in tqdm(enumerate(test_data_loaders[key]),total=len(test_data_loaders[key])):\n",
    "            if i < 3:\n",
    "                if 'label_spe' in data_dict:\n",
    "                    data_dict.pop('label_spe')  # remove the specific label\n",
    "                data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "                # move data to GPU elegantly\n",
    "                for key in data_dict.keys():\n",
    "                    if data_dict[key]!=None:\n",
    "                        data_dict[key]=data_dict[key].cuda()\n",
    "                # model forward without considering gradient computation\n",
    "                # print(data_dict)\n",
    "                with torch.no_grad():\n",
    "                    predictions = inference(model, data_dict)\n",
    "                print(data_dict['label'])\n",
    "                print(predictions['prob'])\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "FaceForensics++\n",
      "dict_keys(['image', 'label', 'landmark', 'mask'])\n",
      "Batch of images shape: torch.Size([2, 6, 224, 224])\n",
      "tensor([[ 0.2857, -0.3205]], grad_fn=<AddBackward0>)\n",
      "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39msoftmax(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 77\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m out \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "from bcos.interpretability import grad_to_img, to_numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "random.seed(2)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# prepare the training data loader\n",
    "# train_data_loader = prepare_training_data(config)\n",
    "config['test_batchSize'] = 2\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "for path in pretrained_paths:\n",
    "    state_dict = torch.load(path)\n",
    "    # Remove \"module.\" prefix\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "        new_state_dict[new_key] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.to(device)#.cuda()\n",
    "    print(next(model.parameters()).device)\n",
    "    # testing for all test data\n",
    "    key = list(test_data_loaders.keys())[0]\n",
    "    print(key)\n",
    "    for i, data_dict in enumerate(test_data_loaders[key]):#img_batch, label_batch in dataloader:\n",
    "        if i<3:\n",
    "            print(data_dict.keys())\n",
    "            img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "            print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "            # device = \"cpu\"\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "            num_batches = img_batch.shape[0]\n",
    "            # Iterate through each image in the batch\n",
    "            for i in range(num_batches):\n",
    "                img = img_batch[i].unsqueeze(0).to(device)#).cuda()  # Process a single image\n",
    "                label = label_batch[i]\n",
    "        \n",
    "                img = img.requires_grad_(True)\n",
    "        \n",
    "                # Zero the gradients\n",
    "                model.zero_grad()\n",
    "        \n",
    "                single_data_dict = {'image':img, 'label':label}\n",
    "                # Forward pass\n",
    "                features = model.features(single_data_dict)\n",
    "                # get the prediction by classifier\n",
    "                out = model.classifier(features)\n",
    "    \n",
    "                # we have to select a target class for which we compute the gradients \n",
    "                # -> simply choose the first one, as it represents the probability that a image is a deepfake\n",
    "                print(out)\n",
    "                print(torch.softmax(out, dim=0))\n",
    "                prob = torch.softmax(out, dim=0)[1]\n",
    "                out = out[1]\n",
    "                # Backward pass\n",
    "                out.backward()\n",
    "        \n",
    "                # Generate attention visualization\n",
    "                att = grad_to_img(img[0], img.grad[0], alpha_percentile=100, smooth=5)\n",
    "                att[..., -1] *= to_numpy(out.sigmoid())\n",
    "        \n",
    "                # Prepare the image and attention map for visualization\n",
    "                att = to_numpy(att)\n",
    "                print(img.shape)\n",
    "                print(\"R\", img[0, 1, :, :])\n",
    "                print(img[0].shape)\n",
    "                # print(img[1].shape)\n",
    "                # print(img[2].shape)\n",
    "                img_np = np.array(to_numpy(img[0, [0, 1, 2]].permute(1, 2, 0)) * 255, dtype=np.uint8)\n",
    "        \n",
    "                # Plot the results\n",
    "                fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "                plt.imshow(img_np, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "                plt.imshow(att, extent=(config['resolution'], 2 * config['resolution'], 0, config['resolution']))\n",
    "                plt.xlim(0, 2 * config['resolution'])\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.title(f\"True Label: {label}, Predictions: {out.sigmoid().item():.2f}\")\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_visible(False)\n",
    "        \n",
    "                plt.show()\n",
    "        else:\n",
    "            break  # Exit after processing the first batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11171/11171 [04:28<00:00, 41.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    key = list(test_data_loaders.keys())[0]\n",
    "    # print(key)\n",
    "    prediction_lists = []\n",
    "    feature_lists = []\n",
    "    label_lists = []\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "        img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "\n",
    "        # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "        # device = \"cpu\"\n",
    "        if 'label_spe' in data_dict:\n",
    "            data_dict.pop('label_spe')  # remove the specific label\n",
    "        data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "        # move data to GPU elegantly\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key]!=None:\n",
    "                data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "\n",
    "\n",
    "        predictions = inference(model, data_dict)\n",
    "        cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "        \n",
    "        label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "        prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "        feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "\n",
    "    # print(prediction_lists)\n",
    "    y_pred = np.array(prediction_lists)\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred >= threshold).astype(int)\n",
    "    y_true = np.array(label_lists)\n",
    "    # print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.18      0.01      0.01      4478\n",
      "        Fake       0.80      0.99      0.89     17864\n",
      "\n",
      "    accuracy                           0.80     22342\n",
      "   macro avg       0.49      0.50      0.45     22342\n",
      "weighted avg       0.68      0.80      0.71     22342\n",
      "\n",
      "[[   29  4449]\n",
      " [  128 17736]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XCeption net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./config/detector/xception.yaml\"\n",
    "\n",
    "weights_base_path = '/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/'\n",
    "additional_args = {'test_batchSize': 12, \n",
    "                   'pretrained':\n",
    "                    f'{weights_base_path}xception_2025-02-06-20-05-09/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-10-17-17/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-12-19-31/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-17-23-41/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-21-26-03/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-21-43-33/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-08-09-13-00/test/avg/ckpt_best.pth'\n",
    "                  }\n",
    "config = load_config(path, additional_args=additional_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "FaceForensics++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1862 [00:00<02:39, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0.5063, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062,\n",
      "        0.5062, 0.5062, 0.5062], device='cuda:0')\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor([0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5063, 0.5062,\n",
      "        0.5063, 0.5062, 0.5062], device='cuda:0')\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "tensor([0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062, 0.5062,\n",
      "        0.5062, 0.5062, 0.5062], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(34)\n",
    "random.seed(34)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "\n",
    "model.cuda()#.to(\"cuda:0\")\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "model.eval()\n",
    "# testing for all test data\n",
    "keys = test_data_loaders.keys()\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    data_dict = test_data_loaders[key].dataset.data_dict\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]),total=len(test_data_loaders[key])):\n",
    "        if i < 3:\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].cuda()\n",
    "            # model forward without considering gradient computation\n",
    "            # print(data_dict)\n",
    "            with torch.no_grad():\n",
    "                predictions = inference(model, data_dict)\n",
    "            print(data_dict['label'])\n",
    "            print(predictions['prob'])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1862/1862 [01:14<00:00, 24.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    key = list(test_data_loaders.keys())[0]\n",
    "    # print(key)\n",
    "    prediction_lists = []\n",
    "    feature_lists = []\n",
    "    label_lists = []\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "        img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "\n",
    "        # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "        # device = \"cpu\"\n",
    "        if 'label_spe' in data_dict:\n",
    "            data_dict.pop('label_spe')  # remove the specific label\n",
    "        data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "        # move data to GPU elegantly\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key]!=None:\n",
    "                data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "\n",
    "\n",
    "        predictions = inference(model, data_dict)\n",
    "        cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "        \n",
    "        label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "        prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "        feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "\n",
    "    # print(prediction_lists)\n",
    "    y_pred = np.array(prediction_lists)\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred >= threshold).astype(int)\n",
    "    y_true = np.array(label_lists)\n",
    "    # print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.00      0.00      0.00      4478\n",
      "        Fake       0.80      1.00      0.89     17864\n",
      "\n",
      "    accuracy                           0.80     22342\n",
      "   macro avg       0.40      0.50      0.44     22342\n",
      "weighted avg       0.64      0.80      0.71     22342\n",
      "\n",
      "[[    0  4478]\n",
      " [    0 17864]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating multiple model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCOS RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.resnet34_bcos_detector:Load pretrained model successfully!\n",
      "  0%|          | 0/1862 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# check performance of all model runs\n",
    "weights_base_path = '/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/resnet_from_scratch_runs/logs/'\n",
    "runs = [f'{weights_base_path}resnet34_bcos_2025-02-05-14-05-08/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-05-16-31-48/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-05-18-32-54/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-06-19-46-26/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-09-30-34/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-12-02-12/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-17-02-26/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-21-26-03/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-08-09-15-43/test/avg/ckpt_best.pth']              \n",
    "\n",
    "for model_run in runs:\n",
    "    path = \"./config/detector/resnet34_bcos.yaml\"\n",
    "    \n",
    "    additional_args = {'test_batchSize': 12, \n",
    "                       'pretrained':model_run}\n",
    "    config = load_config(path, additional_args=additional_args)\n",
    "    test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "    # prepare the model (detector)\n",
    "    model_class = DETECTOR[config['model_name']]\n",
    "    model = model_class(config)\n",
    "    # Set device to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Lists to store all predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        key = list(test_data_loaders.keys())[0]\n",
    "        # print(key)\n",
    "        prediction_lists = []\n",
    "        feature_lists = []\n",
    "        label_lists = []\n",
    "        for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "            img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "            # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "            # device = \"cpu\"\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "    \n",
    "            predictions = inference(model, data_dict)\n",
    "            cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "            \n",
    "            label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "            prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "            feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "    \n",
    "        # print(prediction_lists)\n",
    "        y_pred = np.array(prediction_lists)\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_pred >= threshold).astype(int)\n",
    "        y_true = np.array(label_lists)\n",
    "        # print(y_true)\n",
    "        print(model_run)\n",
    "        # Calculate and print the accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f'Test Accuracy: {accuracy:.2f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-06-20-05-09/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.20      1.00      0.33      4478\n",
      "        Fake       0.00      0.00      0.00     17864\n",
      "\n",
      "    accuracy                           0.20     22342\n",
      "   macro avg       0.10      0.50      0.17     22342\n",
      "weighted avg       0.04      0.20      0.07     22342\n",
      "\n",
      "[[ 4478     0]\n",
      " [17864     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-07-10-17-17/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.20      1.00      0.33      4478\n",
      "        Fake       0.00      0.00      0.00     17864\n",
      "\n",
      "    accuracy                           0.20     22342\n",
      "   macro avg       0.10      0.50      0.17     22342\n",
      "weighted avg       0.04      0.20      0.07     22342\n",
      "\n",
      "[[ 4478     0]\n",
      " [17864     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 24.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-07-12-19-31/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.00      0.00      0.00      4478\n",
      "        Fake       0.80      1.00      0.89     17864\n",
      "\n",
      "    accuracy                           0.80     22342\n",
      "   macro avg       0.40      0.50      0.44     22342\n",
      "weighted avg       0.64      0.80      0.71     22342\n",
      "\n",
      "[[    0  4478]\n",
      " [    0 17864]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-07-17-23-41/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.20      1.00      0.33      4478\n",
      "        Fake       0.00      0.00      0.00     17864\n",
      "\n",
      "    accuracy                           0.20     22342\n",
      "   macro avg       0.10      0.50      0.17     22342\n",
      "weighted avg       0.04      0.20      0.07     22342\n",
      "\n",
      "[[ 4478     0]\n",
      " [17864     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-07-21-26-03/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.00      0.00      0.00      4478\n",
      "        Fake       0.80      1.00      0.89     17864\n",
      "\n",
      "    accuracy                           0.80     22342\n",
      "   macro avg       0.40      0.50      0.44     22342\n",
      "weighted avg       0.64      0.80      0.71     22342\n",
      "\n",
      "[[    0  4478]\n",
      " [    0 17864]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-07-21-43-33/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.00      0.00      0.00      4478\n",
      "        Fake       0.80      1.00      0.89     17864\n",
      "\n",
      "    accuracy                           0.80     22342\n",
      "   macro avg       0.40      0.50      0.44     22342\n",
      "weighted avg       0.64      0.80      0.71     22342\n",
      "\n",
      "[[    0  4478]\n",
      " [    0 17864]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detectors.xception_detector:Load pretrained model successfully!\n",
      "100%|██████████| 1862/1862 [01:14<00:00, 24.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/xception_2025-02-08-09-13-00/test/avg/ckpt_best.pth\n",
      "Test Accuracy: 0.20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.20      1.00      0.33      4478\n",
      "        Fake       0.00      0.00      0.00     17864\n",
      "\n",
      "    accuracy                           0.20     22342\n",
      "   macro avg       0.10      0.50      0.17     22342\n",
      "weighted avg       0.04      0.20      0.07     22342\n",
      "\n",
      "[[ 4478     0]\n",
      " [17864     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check performance of all model runs\n",
    "weights_base_path = '/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/'\n",
    "runs = [f'{weights_base_path}xception_2025-02-06-20-05-09/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-10-17-17/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-12-19-31/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-17-23-41/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-21-26-03/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-21-43-33/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-08-09-13-00/test/avg/ckpt_best.pth']\n",
    "                      \n",
    "\n",
    "for model_run in runs:\n",
    "    path = \"./config/detector/xception.yaml\"\n",
    "    \n",
    "    additional_args = {'test_batchSize': 12, \n",
    "                       'pretrained':model_run}\n",
    "    config = load_config(path, additional_args=additional_args)\n",
    "\n",
    "    test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "    # prepare the model (detector)\n",
    "    model_class = DETECTOR[config['model_name']]\n",
    "    model = model_class(config)\n",
    "\n",
    "    # Set device to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Lists to store all predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        key = list(test_data_loaders.keys())[0]\n",
    "        # print(key)\n",
    "        prediction_lists = []\n",
    "        feature_lists = []\n",
    "        label_lists = []\n",
    "        for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "            img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "            # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "            # device = \"cpu\"\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "    \n",
    "            predictions = inference(model, data_dict)\n",
    "            cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "            \n",
    "            label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "            prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "            feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "    \n",
    "        # print(prediction_lists)\n",
    "        y_pred = np.array(prediction_lists)\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_pred >= threshold).astype(int)\n",
    "        y_true = np.array(label_lists)\n",
    "        # print(y_true)\n",
    "        print(model_run)\n",
    "        # Calculate and print the accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f'Test Accuracy: {accuracy:.2f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter)",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
