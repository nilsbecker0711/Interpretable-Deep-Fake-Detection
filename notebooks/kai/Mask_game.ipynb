{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d151675a-c6cc-4890-ab77-a5ad2e86c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 17:18:25.611885: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-25 17:18:25.626013: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745594305.640541 2386888 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745594305.645417 2386888 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-25 17:18:25.665221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/bwhpc/common/jupyter/ai/2025-02-20/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/bwhpc/common/jupyter/ai/2025-02-20/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" \u001b[39;00m\n\u001b[1;32m     23\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.py\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_seed, prepare_training_data, prepare_testing_data, choose_optimizer, choose_scheduler, choose_metric\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcudnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcudnn\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdist\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/training/train.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdetectors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DETECTOR\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_metric_for_print\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_logger, RankFilter\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/training/dataset/__init__.py:20\u001b[0m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(project_root_dir)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\" from .I2G_dataset import I2GDataset\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mfrom .iid_dataset import IIDDataset\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mfrom .abstract_dataset import DeepfakeAbstractBaseDataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mfrom .lsda_dataset import LSDADataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mfrom .tall_dataset import TALLDataset \"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepfakeAbstractBaseDataset\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#from .tall_dataset import TALLDataset\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb_cos_pp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepfakeBcosDataset\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/Interpretable-Deep-Fake-Detection/training/dataset/abstract_dataset.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m T\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mA\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbu\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IsotropicResize\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/albumentations/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/albumentations/core/composition.py:8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeypoints_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeypointsProcessor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SerializableMeta, get_shortest_class_fullname\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_metaclass\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/albumentations/augmentations/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeypoints_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbbox_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# New transformations goes to individual files listed below\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/albumentations/augmentations/functional.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequence, Optional, Union\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeypoints_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m angle_to_2pi_range\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/skimage/__init__.py:157\u001b[0m\n\u001b[1;32m    154\u001b[0m         _raise_build_error(e)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# All skimage root imports go here\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtype\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (img_as_float32,\n\u001b[1;32m    158\u001b[0m                              img_as_float64,\n\u001b[1;32m    159\u001b[0m                              img_as_float,\n\u001b[1;32m    160\u001b[0m                              img_as_int,\n\u001b[1;32m    161\u001b[0m                              img_as_uint,\n\u001b[1;32m    162\u001b[0m                              img_as_ubyte,\n\u001b[1;32m    163\u001b[0m                              img_as_bool,\n\u001b[1;32m    164\u001b[0m                              dtype_limits)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookfor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lookfor\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m __version__:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Append last commit date and hash to dev version information, if available\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/skimage/util/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtype\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (img_as_float32, img_as_float64, img_as_float,\n\u001b[1;32m      5\u001b[0m                     img_as_int, img_as_uint, img_as_ubyte,\n\u001b[1;32m      6\u001b[0m                     img_as_bool, dtype_limits)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m view_as_blocks, view_as_windows\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnoise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m random_noise\n",
      "File \u001b[0;32m/pfs/data6/home/ma/ma_ma/ma_kreffert/jupyter_venv/lib64/python3.11/site-packages/skimage/util/dtype.py:27\u001b[0m\n\u001b[1;32m     18\u001b[0m _integer_types \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mbyte, np\u001b[38;5;241m.\u001b[39mubyte,          \u001b[38;5;66;03m# 8 bits\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                   np\u001b[38;5;241m.\u001b[39mshort, np\u001b[38;5;241m.\u001b[39mushort,        \u001b[38;5;66;03m# 16 bits\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                   np\u001b[38;5;241m.\u001b[39mintc, np\u001b[38;5;241m.\u001b[39muintc,          \u001b[38;5;66;03m# 16 or 32 or 64 bits\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                   \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mint_, np\u001b[38;5;241m.\u001b[39muint,      \u001b[38;5;66;03m# 32 or 64 bits\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                   np\u001b[38;5;241m.\u001b[39mlonglong, np\u001b[38;5;241m.\u001b[39mulonglong)  \u001b[38;5;66;03m# 64 bits\u001b[39;00m\n\u001b[1;32m     23\u001b[0m _integer_ranges \u001b[38;5;241m=\u001b[39m {t: (np\u001b[38;5;241m.\u001b[39miinfo(t)\u001b[38;5;241m.\u001b[39mmin, np\u001b[38;5;241m.\u001b[39miinfo(t)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m     24\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m _integer_types}\n\u001b[1;32m     25\u001b[0m dtype_range \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mbool\u001b[39m: (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     26\u001b[0m                np\u001b[38;5;241m.\u001b[39mbool_: (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m---> 27\u001b[0m                \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool8\u001b[49m: (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     28\u001b[0m                \u001b[38;5;28mfloat\u001b[39m: (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     29\u001b[0m                np\u001b[38;5;241m.\u001b[39mfloat_: (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     30\u001b[0m                np\u001b[38;5;241m.\u001b[39mfloat16: (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     31\u001b[0m                np\u001b[38;5;241m.\u001b[39mfloat32: (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     32\u001b[0m                np\u001b[38;5;241m.\u001b[39mfloat64: (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)}\n\u001b[1;32m     33\u001b[0m dtype_range\u001b[38;5;241m.\u001b[39mupdate(_integer_ranges)\n\u001b[1;32m     35\u001b[0m _supported_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dtype_range\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/ai/2025-02-20/lib/python3.11/site-packages/numpy/__init__.py:410\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool8'"
     ]
    }
   ],
   "source": [
    "from utils import load_config\n",
    "import yaml\n",
    "import os\n",
    "# print(os.getcwd())\n",
    "os.chdir('../../../Interpretable-Deep-Fake-Detection/training/')\n",
    "import torch\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(34)\n",
    "random.seed(34)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "torch.cuda.empty_cache()\n",
    "# torch.cuda.reset_peak_memory_stats()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" \n",
    "sys.argv = [\"train.py\"]\n",
    "from train import init_seed, prepare_training_data, prepare_testing_data, choose_optimizer, choose_scheduler, choose_metric\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from datetime import timedelta\n",
    "from detectors import DETECTOR\n",
    "# from trainer.trainer import Trainer\n",
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a932a47-4c22-4e42-880d-384ee73d5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/pfs/work7/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/weights/'\n",
    "pretrained_paths = [f'{base_path}resnet34_v2_minimal/b125_03_10_16_34_15_ckpt_best.pth',\n",
    "                   f'{base_path}b2_ckpt_best.pth',\n",
    "                #    f'{base_path}resnet34_v2_minimal/'\n",
    "                    f'{base_path}resnet34_v2_minimal/b2_03_17_14_42_12_ckpt_best.pth',\n",
    "                   f'{base_path}resnet34_v2_minimal/b25_03-31-21-15-12_ckpt_best.pth',\n",
    "                   f'{base_path}resnet34_03_18_16_59_57_ckpt_best.pth']\n",
    "additional_args = {'test_batchSize': 8,\n",
    "                  'pretrained': pretrained_paths[0],\n",
    "                  'backbone_config':{'b': 1.25}\n",
    "                  }\n",
    "b_list = [1.25, 2, 2, 2.5, 0]\n",
    "configs = []\n",
    "for i, path in enumerate(pretrained_paths):\n",
    "    additional_args['pretrained'] = path\n",
    "    if b_list[i]>0: \n",
    "        additional_args['backbone_config'] = {'b':b_list[i]}\n",
    "        config_path = \"./config/detector/resnet34_bcos_v2_minimal.yaml\"\n",
    "    else:\n",
    "        config_path = \"./config/detector/resnet34.yaml\"\n",
    "        additional_args['compression'] = 'c40'\n",
    "    config = load_config(path, additional_args=additional_args)\n",
    "    configs.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4826b44-82ce-441d-a57b-bdcced1c7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from bcos.interpretability import grad_to_img, to_numpy\n",
    "def mask_game(mask, heatmap):\n",
    "    if isinstance(heatmap, torch.Tensor):\n",
    "        heatmap = heatmap.cpu().numpy()  # Convert tensor to numpy array\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()  # Convert tensor to numpy array\n",
    "    heatmap = heatmap[:, :, -1:].copy()\n",
    "    # Ensure both are in the 0-1 range (binary)\n",
    "    if np.max(heatmap) > 1:  # If values are in 0-255 (image format), threshold to 0 or 1\n",
    "        print(\"heatmap range may be wrong\")\n",
    "        heatmap = np.where(heatmap > 0, 1, 0)\n",
    "\n",
    "    if np.max(mask) > 1:  # If values are in 0-255 (image format), threshold to 0 or 1\n",
    "        print(\"mask range may be wrong\")\n",
    "        mask = np.where(mask > 0, 1, 0)\n",
    "        \n",
    "    # assuming mask is a tensor or numpy array\n",
    "    correct_pixels = np.sum((heatmap == 1) & (mask == 1))  # Pixels that are both predicted as \"1\" and ground truth \"1\"\n",
    "    # print(np.array((heatmap == 1) & (mask == 1)).shape)\n",
    "    total_predicted_pixels = np.sum(heatmap == 1)  # Total ground truth pixels that are part of the mask\n",
    "    # print(np.array(heatmap == 1).shape)\n",
    "    # Step 5: Compute the performance metric (e.g., accuracy)\n",
    "    accuracy = correct_pixels / total_predicted_pixels if total_predicted_pixels > 0 else 0  # Accuracy based on mask region\n",
    "    \n",
    "    # Optionally, calculate Intersection over Union (IoU) for better performance measurement\n",
    "    intersection = correct_pixels\n",
    "    union = np.sum((heatmap == 1) | (mask == 1))  # Union of predicted mask and ground truth mask\n",
    "    iou = intersection / union if union > 0 else 0  # IoU\n",
    "    \n",
    "    # Print performance results\n",
    "    # print(f\"Correct Pixels: {correct_pixels}\")\n",
    "    # print(f\"Total Mask Pixels: {total_predicted_pixels}\")\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Intersection over Union (IoU): {iou:.4f}\")\n",
    "    return accuracy.round(4)\n",
    "\n",
    "config = config_1\n",
    "config['ddp'] = False\n",
    "config['with_mask'] = True\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "num_plots = 10\n",
    "threshold = 0.5\n",
    "device = 'cpu'\n",
    "fig, axes = plt.subplots(num_plots, 5, figsize=(10, num_plots*3))\n",
    "for key in ['FaceForensics++']:#test_data_loaders.keys():\n",
    "         # Prepare the model (detector)\n",
    "        model_class = DETECTOR[config['model_name']]\n",
    "        model = model_class(config)\n",
    "        state_dict = torch.load(config['pretrained'])\n",
    "        \n",
    "        # Remove \"module.\" prefix if present in the state_dict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "            new_state_dict[new_key] = v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        model.to(device)\n",
    "        for i, data_dict in enumerate(test_data_loaders[key]):\n",
    "            if i< num_plots:\n",
    "                \n",
    "                # Process data and ensure labels are binary (0 or 1)\n",
    "                img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "                if 'label_spe' in data_dict:\n",
    "                    data_dict.pop('label_spe')\n",
    "                data_dict['label'] = torch.where(data_dict['label'] != 0, 1, 0)\n",
    "\n",
    "                for key in data_dict.keys():\n",
    "                    if data_dict[key] is not None:\n",
    "                        data_dict[key] = data_dict[key].to(device)\n",
    "\n",
    "                # Take the first image and process it\n",
    "                img = img_batch[0].unsqueeze(0).to(device)  # Process a single image\n",
    "                label = label_batch[0]\n",
    "                mask = mask[0].to('cpu')\n",
    "\n",
    "                # Generate explanation (replace with your actual explanation function)\n",
    "                model.backbone.eval()\n",
    "                explanation = model.backbone.explain(img)\n",
    "\n",
    "                # Apply threshold to the explanation heatmap to binarize it\n",
    "                explanation_map = explanation['explanation'][:, :, :].copy()\n",
    "                explanation_map[:, :, -1] = (explanation_map[:, :, -1] > threshold).astype(np.uint8)  # Convert to 0 or 1 based on threshold\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                img_np = np.array(to_numpy(img[0, [0, 1, 2]].permute(1, 2, 0)) * 255, dtype=np.uint8)\n",
    "                row_idx = i \n",
    "                # Plot the original image on the left subplot\n",
    "                axes[row_idx, 0].imshow(img_np, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "                # axes[row_idx, 0].set_title(f\"Label {label}\")\n",
    "                #axes[row_idx, col_idx].set_xlim(0, config['resolution'])\n",
    "                axes[row_idx, 0].set_xticks([])\n",
    "                axes[row_idx, 0].set_yticks([])\n",
    "                if mask.max()>0.1:\n",
    "                    # print(mask.shape)\n",
    "                    # print(mask.max())\n",
    "                    mask_np = np.array(mask*255)#to_numpy(mask[0, [0, 1, 2]].permute(1, 2, 0)) * 255, dtype=np.uint8)\n",
    "    \n",
    "                    # Plot the original image on the left subplot\n",
    "                    axes[row_idx, 1].imshow(mask_np, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "                    # axes[row_idx, 1].set_title(f\"Label {label}\")\n",
    "                    #axes[row_idx, col_idx].set_xlim(0, config['resolution'])\n",
    "                    axes[row_idx, 1].set_xticks([])\n",
    "                    axes[row_idx, 1].set_yticks([])\n",
    "\n",
    "                    axes[row_idx, 2].imshow(explanation_map, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "                    axes[row_idx, 2].imshow(mask_np, cmap='jet', alpha=0.5, extent=(0, config['resolution'], 0, config['resolution']))  # Add alpha for transparency\n",
    "                    accuracy = mask_game(mask, explanation_map)\n",
    "                    axes[row_idx, 2].set_title(f\"Accuracy {accuracy}\")\n",
    "                    #axes[row_idx, col_idx].set_xlim(0, config['resolution'])\n",
    "                    axes[row_idx, 2].set_xticks([])\n",
    "                    axes[row_idx, 2].set_yticks([])\n",
    "\n",
    "                    mask = mask.cpu().numpy()\n",
    "                    correct = np.array((explanation_map == 1) & (mask == 1))\n",
    "                    # correct = np.array((explanation_map == 1))\n",
    "                    correct = correct*255\n",
    "                    axes[row_idx, 3].imshow(correct, cmap='jet', alpha=0.5, extent=(0, config['resolution'], 0, config['resolution']))  # Add alpha for transparency\n",
    "                    axes[row_idx, 3].set_title(\"Correct predicted\")\n",
    "                    #axes[row_idx, col_idx].set_xlim(0, config['resolution'])\n",
    "                    axes[row_idx, 3].set_xticks([])\n",
    "                    axes[row_idx, 3].set_yticks([])\n",
    "                    \n",
    "                    wrong = np.array((explanation_map == 1) & (mask != 1))\n",
    "                    # correct = np.array((explanation_map == 1))\n",
    "                    wrong = wrong*255\n",
    "                    axes[row_idx, 4].imshow(wrong, cmap='jet', alpha=0.5, extent=(0, config['resolution'], 0, config['resolution']))  # Add alpha for transparency\n",
    "                    axes[row_idx, 4].set_title(\"False predicted\")\n",
    "                    #axes[row_idx, col_idx].set_xlim(0, config['resolution'])\n",
    "                    axes[row_idx, 4].set_xticks([])\n",
    "                    axes[row_idx, 4].set_yticks([])\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9822c60-ed01-4f94-be49-8bfdbb6b12b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0cbdc0-835c-4b81-b7e3-47d727d54198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter venv)",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
