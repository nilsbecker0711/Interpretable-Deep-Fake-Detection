{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load devel/cuda/12.4\n",
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# print(os.getcwd())\n",
    "os.chdir('/pfs/data5/home/ma/ma_ma/ma_tofuchs/Interpretable-Deep-Fake-Detection/training')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.set_device(0)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" \n",
    "sys.argv = [\"train.py\"]\n",
    "from train import init_seed, prepare_training_data, prepare_testing_data, choose_optimizer, choose_scheduler, choose_metric\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from datetime import timedelta\n",
    "from detectors import DETECTOR\n",
    "from trainer.trainer import Trainer\n",
    "\n",
    "\n",
    "def load_config(path, additional_args = {}):\n",
    "    # parse options and load config\n",
    "    with open(path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    try:# KAI: added this, to ensure it finds the config file\n",
    "        with open('./training/config/train_config.yaml', 'r') as f:\n",
    "            config2 = yaml.safe_load(f)\n",
    "    except FileNotFoundError:\n",
    "        with open(os.path.expanduser('~/Interpretable-Deep-Fake-Detection/training/config/train_config.yaml'), 'r') as f:\n",
    "            config2 = yaml.safe_load(f)\n",
    "    if 'label_dict' in config:\n",
    "        config2['label_dict']=config['label_dict']\n",
    "    config.update(config2)\n",
    "    # config['local_rank']=args.local_rank\n",
    "    if config['dry_run']:\n",
    "        config['nEpochs'] = 0\n",
    "        config['save_feat']=False\n",
    "    for key, value in additional_args.items():\n",
    "        config[key] = value\n",
    "    return config\n",
    "\n",
    "\n",
    "path = \"./config/detector/resnet34_bcos.yaml\"\n",
    "additional_args = {'test_batchSize': 4}\n",
    "config = load_config(path, additional_args=additional_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.test import test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(34)\n",
    "random.seed(34)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "\n",
    "model.cuda()#.to(\"cuda:0\")\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "model.eval()\n",
    "# testing for all test data\n",
    "keys = test_data_loaders.keys()\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    data_dict = test_data_loaders[key].dataset.data_dict\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]),total=len(test_data_loaders[key])):\n",
    "        if i < 3:\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].cuda()\n",
    "            # model forward without considering gradient computation\n",
    "            # print(data_dict)\n",
    "            with torch.no_grad():\n",
    "                predictions = inference(model, data_dict)\n",
    "            print(data_dict['label'])\n",
    "            print(predictions['prob'])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcos.interpretability import grad_to_img, to_numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from test import test_epoch, test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "random.seed(2)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# prepare the training data loader\n",
    "# train_data_loader = prepare_training_data(config)\n",
    "config['test_batchSize'] = 2\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config, mode=\"test\")\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "\n",
    "model.to(device)#.cuda()\n",
    "print(next(model.parameters()).device)\n",
    "# testing for all test data\n",
    "key = list(test_data_loaders.keys())[0]\n",
    "print(key)\n",
    "for i, data_dict in enumerate(test_data_loaders[key]):#img_batch, label_batch in dataloader:\n",
    "    if i<3:\n",
    "        print(data_dict.keys())\n",
    "        img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "\n",
    "        print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "        # device = \"cpu\"\n",
    "        if 'label_spe' in data_dict:\n",
    "            data_dict.pop('label_spe')  # remove the specific label\n",
    "        data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "        # move data to GPU elegantly\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key]!=None:\n",
    "                data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "\n",
    "        num_batches = img_batch.shape[0]\n",
    "        # Iterate through each image in the batch\n",
    "        for i in range(num_batches):\n",
    "            img = img_batch[i].unsqueeze(0).to(device)#).cuda()  # Process a single image\n",
    "            label = label_batch[i]\n",
    "    \n",
    "            img = img.requires_grad_(True)\n",
    "    \n",
    "            # Zero the gradients\n",
    "            model.zero_grad()\n",
    "    \n",
    "            single_data_dict = {'image':img, 'label':label}\n",
    "            # Forward pass\n",
    "            features = model.features(single_data_dict)\n",
    "            # get the prediction by classifier\n",
    "            out = model.classifier(features)\n",
    "\n",
    "            # we have to select a target class for which we compute the gradients \n",
    "            # -> simply choose the first one, as it represents the probability that a image is a deepfake\n",
    "            prob = torch.softmax(out, dim=0)[1]\n",
    "            out = out[1]\n",
    "            # Backward pass\n",
    "            out.backward()\n",
    "    \n",
    "            # Generate attention visualization\n",
    "            att = grad_to_img(img[0], img.grad[0], alpha_percentile=100, smooth=5)\n",
    "            att[..., -1] *= to_numpy(out.sigmoid())\n",
    "    \n",
    "            # Prepare the image and attention map for visualization\n",
    "            att = to_numpy(att)\n",
    "            print(img.shape)\n",
    "            print(\"R\", img[0, 1, :, :])\n",
    "            print(img[0].shape)\n",
    "            # print(img[1].shape)\n",
    "            # print(img[2].shape)\n",
    "            img_np = np.array(to_numpy(img[0, [0, 1, 2]].permute(1, 2, 0)) * 255, dtype=np.uint8)\n",
    "    \n",
    "            # Plot the results\n",
    "            fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "            plt.imshow(img_np, extent=(0, config['resolution'], 0, config['resolution']))\n",
    "            plt.imshow(att, extent=(config['resolution'], 2 * config['resolution'], 0, config['resolution']))\n",
    "            plt.xlim(0, 2 * config['resolution'])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(f\"True Label: {label}, Predictions: {out.sigmoid().item():.2f}\")\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "    \n",
    "            plt.show()\n",
    "    else:\n",
    "        break  # Exit after processing the first batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    key = list(test_data_loaders.keys())[0]\n",
    "    # print(key)\n",
    "    prediction_lists = []\n",
    "    feature_lists = []\n",
    "    label_lists = []\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "        img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "\n",
    "        # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "        # device = \"cpu\"\n",
    "        if 'label_spe' in data_dict:\n",
    "            data_dict.pop('label_spe')  # remove the specific label\n",
    "        data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "        # move data to GPU elegantly\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key]!=None:\n",
    "                data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "\n",
    "\n",
    "        predictions = inference(model, data_dict)\n",
    "        cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "        \n",
    "        label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "        prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "        feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "\n",
    "    # print(prediction_lists)\n",
    "    y_pred = np.array(prediction_lists)\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred >= threshold).astype(int)\n",
    "    y_true = np.array(label_lists)\n",
    "    # print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XCeption net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./config/detector/xception.yaml\"\n",
    "#/home/ma/ma_ma/ma_tofuchs/\n",
    "\n",
    "weights_base_path = '/pfs/work7/workspace/scratch/ma_tischuet-team_project_explainable_deepfakes/weights/xception/logs/'\n",
    "additional_args = {'test_batchSize': 12, \n",
    "                   'pretrained':\n",
    "                    #f'{weights_base_path}xception_best.pth'\n",
    "                    f'{weights_base_path}xception_2025-02-06-20-05-09/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-10-17-17/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-12-19-31/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-17-23-41/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-21-26-03/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-21-43-33/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-08-09-13-00/test/avg/ckpt_best.pth'\n",
    "                  }\n",
    "config = load_config(path, additional_args=additional_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.test import test_one_dataset, test_epoch, inference\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# init seed\n",
    "# init_seed(config)\n",
    "\n",
    "torch.manual_seed(34)\n",
    "random.seed(34)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for strict reproducibility\n",
    "\n",
    "# prepare the testing data loader\n",
    "test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "\n",
    "#model.cuda()#.to(\"cuda:0\")\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "model.eval()\n",
    "# testing for all test data\n",
    "keys = test_data_loaders.keys()\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    data_dict = test_data_loaders[key].dataset.data_dict\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]),total=len(test_data_loaders[key])):\n",
    "        if i < 3:\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].cuda()\n",
    "            # model forward without considering gradient computation\n",
    "            # print(data_dict)\n",
    "            with torch.no_grad():\n",
    "                predictions = inference(model, data_dict)\n",
    "            print(data_dict['label'])\n",
    "            print(predictions['prob'])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    key = list(test_data_loaders.keys())[0]\n",
    "    # print(key)\n",
    "    prediction_lists = []\n",
    "    feature_lists = []\n",
    "    label_lists = []\n",
    "    for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "        img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "\n",
    "        # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "        # device = \"cpu\"\n",
    "        if 'label_spe' in data_dict:\n",
    "            data_dict.pop('label_spe')  # remove the specific label\n",
    "        data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "        # move data to GPU elegantly\n",
    "        for key in data_dict.keys():\n",
    "            if data_dict[key]!=None:\n",
    "                data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "\n",
    "\n",
    "        predictions = inference(model, data_dict)\n",
    "        cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "        \n",
    "        label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "        prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "        feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "\n",
    "    # print(prediction_lists)\n",
    "    y_pred = np.array(prediction_lists)\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred >= threshold).astype(int)\n",
    "    y_true = np.array(label_lists)\n",
    "    # print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating multiple model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCOS RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance of all model runs\n",
    "weights_base_path = '/home/ma/ma_ma/ma_tofuchs/Interpretable-Deep-Fake-Detection/BWCluster/resnet_from_scratch_runs/logs/'\n",
    "runs = [f'{weights_base_path}resnet34_bcos_2025-02-05-14-05-08/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-05-16-31-48/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-05-18-32-54/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-06-19-46-26/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-09-30-34/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-12-02-12/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-17-02-26/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-07-21-26-03/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}resnet34_bcos_2025-02-08-09-15-43/test/avg/ckpt_best.pth']              \n",
    "\n",
    "for model_run in runs:\n",
    "    path = \"./config/detector/resnet34_bcos.yaml\"\n",
    "    \n",
    "    additional_args = {'test_batchSize': 12, \n",
    "                       'pretrained':model_run}\n",
    "    config = load_config(path, additional_args=additional_args)\n",
    "    test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "    # prepare the model (detector)\n",
    "    model_class = DETECTOR[config['model_name']]\n",
    "    model = model_class(config)\n",
    "    # Set device to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Lists to store all predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        key = list(test_data_loaders.keys())[0]\n",
    "        # print(key)\n",
    "        prediction_lists = []\n",
    "        feature_lists = []\n",
    "        label_lists = []\n",
    "        for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "            img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "            # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "            # device = \"cpu\"\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "    \n",
    "            predictions = inference(model, data_dict)\n",
    "            cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "            \n",
    "            label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "            prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "            feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "    \n",
    "        # print(prediction_lists)\n",
    "        y_pred = np.array(prediction_lists)\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_pred >= threshold).astype(int)\n",
    "        y_true = np.array(label_lists)\n",
    "        # print(y_true)\n",
    "        print(model_run)\n",
    "        # Calculate and print the accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f'Test Accuracy: {accuracy:.2f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance of all model runs\n",
    "weights_base_path = '/home/ma/ma_ma/ma_tofuchs/Interpretable-Deep-Fake-Detection/BWCluster/xception/logs/'\n",
    "runs = [f'{weights_base_path}xception_2025-02-06-20-05-09/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-10-17-17/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-12-19-31/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-17-23-41/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-21-26-03/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-07-21-43-33/test/avg/ckpt_best.pth',\n",
    "        f'{weights_base_path}xception_2025-02-08-09-13-00/test/avg/ckpt_best.pth']\n",
    "                      \n",
    "\n",
    "for model_run in runs:\n",
    "    path = \"./config/detector/xception.yaml\"\n",
    "    \n",
    "    additional_args = {'test_batchSize': 12, \n",
    "                       'pretrained':model_run}\n",
    "    config = load_config(path, additional_args=additional_args)\n",
    "\n",
    "    test_data_loaders = prepare_testing_data(config)\n",
    "\n",
    "    # prepare the model (detector)\n",
    "    model_class = DETECTOR[config['model_name']]\n",
    "    model = model_class(config)\n",
    "\n",
    "    # Set device to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Lists to store all predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        key = list(test_data_loaders.keys())[0]\n",
    "        # print(key)\n",
    "        prediction_lists = []\n",
    "        feature_lists = []\n",
    "        label_lists = []\n",
    "        for i, data_dict in tqdm(enumerate(test_data_loaders[key]), total=len(test_data_loaders[key])):#img_batch, label_batch in dataloader:\n",
    "            img_batch, label_batch, landmark, mask = (data_dict[k] for k in ['image', 'label', 'landmark', 'mask'])\n",
    "    \n",
    "            # print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "            # device = \"cpu\"\n",
    "            if 'label_spe' in data_dict:\n",
    "                data_dict.pop('label_spe')  # remove the specific label\n",
    "            data_dict['label'] = torch.where(data_dict['label']!=0, 1, 0)  # fix the label to 0 and 1 only\n",
    "            # move data to GPU elegantly\n",
    "            for key in data_dict.keys():\n",
    "                if data_dict[key]!=None:\n",
    "                    data_dict[key]=data_dict[key].to(device)#cuda()\n",
    "    \n",
    "    \n",
    "            predictions = inference(model, data_dict)\n",
    "            cls, prob, feat = (predictions[k] for k in ['cls', 'prob', 'feat'])\n",
    "            \n",
    "            label_lists += list(data_dict['label'].cpu().detach().numpy())\n",
    "            prediction_lists += list(predictions['prob'].cpu().detach().numpy())\n",
    "            feature_lists += list(predictions['feat'].cpu().detach().numpy())\n",
    "    \n",
    "        # print(prediction_lists)\n",
    "        y_pred = np.array(prediction_lists)\n",
    "        threshold = 0.5\n",
    "        y_pred = (y_pred >= threshold).astype(int)\n",
    "        y_true = np.array(label_lists)\n",
    "        # print(y_true)\n",
    "        print(model_run)\n",
    "        # Calculate and print the accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f'Test Accuracy: {accuracy:.2f}')\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
