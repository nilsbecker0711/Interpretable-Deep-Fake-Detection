{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"/Users/Linus/Desktop/GIThubXAIFDEEPFAKE/Interpretable-Deep-Fake-Detection\")\n",
    "sys.path.append(\"/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2\")\n",
    "#sys.path.append(\"/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/training\")\n",
    "sys.argv = [\"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DETECTOR\n",
      "File \u001b[0;32m~/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/training/detectors/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DETECTOR\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m slowfast\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvgg19_bcos_detector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGGBcosDetector\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet34_detector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResnetDetector\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet34_bcos_detector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResnetBcosDetector\n",
      "File \u001b[0;32m~/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/training/detectors/vgg19_bcos_detector.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_state_dict_from_url\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_metrics_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_metrics_for_train\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/tensorboard/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_vendor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensorboard, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m Version(\n\u001b[1;32m      5\u001b[0m     tensorboard\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m      6\u001b[0m ) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.15\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from training.detectors import DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import XGradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from training.detectors import xception_detector\n",
    "#i needed to append my analysis path to system to access the bcos saved models\n",
    "\n",
    "def load_config(path, additional_args = {}):\n",
    "    # parse options and load config\n",
    "    with open(path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    try:# KAI: added this, to ensure it finds the config file\n",
    "        #with open('/Users/Linus/Desktop/GIThubXAIFDEEPFAKE/Interpretable-Deep-Fake-Detection/training/config/train_config.yaml', 'r') as f:\n",
    "        with open('/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/training/config/train_config.yaml', 'r') as f:\n",
    "            config2 = yaml.safe_load(f)\n",
    "    except FileNotFoundError:\n",
    "        #with open(os.path.expanduser('/Users/Linus/Desktop/GIThubXAIFDEEPFAKE/Interpretable-Deep-Fake-Detection/training/config/train_config.yaml'), 'r') as f:\n",
    "        with open(os.path.expanduser('/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/training/config/train_config.yaml'), 'r') as f:\n",
    "            config2 = yaml.safe_load(f)\n",
    "    if 'label_dict' in config:\n",
    "        config2['label_dict']=config['label_dict']\n",
    "    config.update(config2)\n",
    "    # config['local_rank']=args.local_rank\n",
    "    if config['dry_run']:\n",
    "        config['nEpochs'] = 0\n",
    "        config['save_feat']=False\n",
    "    for key, value in additional_args.items():\n",
    "        config[key] = value\n",
    "    return config\n",
    "\n",
    "#path = \"/Users/Linus/Desktop/GIThubXAIFDEEPFAKE/Interpretable-Deep-Fake-Detection/training/config/detector/xception.yaml\"\n",
    "path = \"/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/training/config/detector/xception.yaml\"\n",
    "additional_args = {'test_batchSize': 12, \n",
    "                   'pretrained':\n",
    "                    #f'/Users/Linus/Desktop/GIThubXAIFDEEPFAKE/Interpretable-Deep-Fake-Detection/weights/resnet/ckpt_best.pth'\n",
    "                    f'/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/weights/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-10-17-17/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-12-19-31/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-17-23-41/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-21-26-03/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-07-21-43-33/test/avg/ckpt_best.pth'\n",
    "                    #f'{weights_base_path}xception_2025-02-08-09-13-00/test/avg/ckpt_best.pth'\n",
    "                  }\n",
    "config = load_config(path, additional_args=additional_args)\n",
    "print(\"Registered models:\", DETECTOR.data.keys())\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laoding in grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyToTensor(transforms.ToTensor):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Same as transforms.ToTensor, except that if input to __call__ is already tensor, the input is returned unchanged\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, input_img):\n",
    "        if not isinstance(input_img, torch.Tensor):\n",
    "            return super().__call__(input_img)\n",
    "        return input_img\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize if necessary\n",
    "    MyToTensor(),            # Converts image to tensor if not already          \n",
    "])\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, folder_paths, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_paths (dict): Dictionary where keys are folder paths, and values are the labels.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.image_files = []  # Store (image_path, label) tuples\n",
    "        for fp, label in folder_paths.items():\n",
    "            # List all subdirectories within the folder\n",
    "            subfolders = [os.path.join(fp, d) for d in os.listdir(fp) if os.path.isdir(os.path.join(fp, d))]\n",
    "        # Include images from the root directory as well as subfolders\n",
    "        self.image_files.extend(\n",
    "            [(os.path.join(fp, f), label) for f in os.listdir(fp) if f.endswith((\".png\", \".jpg\"))]\n",
    "        )\n",
    "\n",
    "        for folder_path in subfolders:\n",
    "            self.image_files.extend(\n",
    "                [(os.path.join(folder_path, f), label) for f in os.listdir(folder_path) if f.endswith((\".png\", \".jpg\"))]\n",
    "            )\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.image_files[idx]  # Get image path and its label\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, img_path\n",
    "\n",
    "\n",
    "#file_path_deepfakebench = {\"/Users/Linus/Desktop/GIThubXAIFDEEPFAKE/Interpretable-Deep-Fake-Detection/datasets/GPG_grids/3ch\": 1}\n",
    "file_path_deepfakebench = {\"/Users/msrobin/GitHub Repositorys/Interpretable-Deep-Fake-Detection-2/datasets/2x2_images\": 1}\n",
    "\n",
    "dataset = CustomImageDataset(file_path_deepfakebench, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for images, label, img_path in dataloader:\n",
    "    print(f\"Batch of images shape: {images.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for img_batch, label_batch, path_batch in dataloader:\n",
    "    print(f\"Batch of images shape: {img_batch.shape}\")\n",
    "\n",
    "    # Iterate through the first 5 images in the batch\n",
    "    num_images = min(len(img_batch), 20)\n",
    "    for i in range(num_images):\n",
    "        img = img_batch[i].unsqueeze(0).to(device)  # Process a single image\n",
    "        label = label_batch[i]\n",
    "        img_path = path_batch[i]\n",
    "        img = img.requires_grad_(True)\n",
    "        \n",
    "        data_dict = {'image': img, 'label': label}\n",
    "        \n",
    "        model.zero_grad()\n",
    "        out = model(data_dict)\n",
    "        \n",
    "        prob = out['prob']\n",
    "        print('predicted prob', prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X Grad Cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
