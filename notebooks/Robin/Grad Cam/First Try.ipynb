{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X-Grad-Cam: Instead of global average pooling, XGrad-CAM normalizes the gradients using a term that adjusts for feature importance per location.\n",
    "This normalization helps refine the heatmap, making it sharper and more localized.\n",
    "More accurate feature weighting than Grad-CAM.\n",
    "Slightly more computationally expensive than standard Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytorch_grad_cam.base_cam import BaseCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGradCAM(BaseCAM):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            target_layers,\n",
    "            reshape_transform=None):\n",
    "        super(\n",
    "            XGradCAM,\n",
    "            self).__init__(\n",
    "            model,\n",
    "            target_layers,\n",
    "            reshape_transform)\n",
    "\n",
    "    def get_cam_weights(self,\n",
    "                        input_tensor,\n",
    "                        target_layer,\n",
    "                        target_category,\n",
    "                        activations,\n",
    "                        grads):\n",
    "        sum_activations = np.sum(activations, axis=(2, 3))\n",
    "        eps = 1e-7\n",
    "        weights = grads * activations / \\\n",
    "            (sum_activations[:, :, None, None] + eps)\n",
    "        weights = weights.sum(axis=(2, 3))\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_grad_cam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGradCAM\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import XGradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path, additional_args={}):\n",
    "    with open(path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "path = \"./training/config/detector/xception.yaml\"\n",
    "additional_args = {'test_batchSize': 12, 'pretrained': './weights/ckpt_best.pth'}\n",
    "config = load_config(path, additional_args=additional_args)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "model.eval()\n",
    "\n",
    "# Define target layer for Grad-CAM (refined for better feature extraction)\n",
    "TARGET_LAYER = model.backbone.features[-1]\n",
    "\n",
    "def apply_xgrad_cam(model, images, target_class=1):\n",
    "    \"\"\"Generate XGrad-CAM heatmap for a batch of images.\"\"\"\n",
    "    cam = XGradCAM(model=model, target_layers=[TARGET_LAYER])\n",
    "    targets = [ClassifierOutputTarget(target_class)]\n",
    "    grayscale_cam = cam(input_tensor=images, targets=targets)\n",
    "    return grayscale_cam\n",
    "\n",
    "def overlay_heatmap(image, cam):\n",
    "    \"\"\"Overlay XGrad-CAM heatmap on the original image.\"\"\"\n",
    "    image = np.transpose(image.numpy(), (1, 2, 0))\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(image, 0.6, heatmap / 255.0, 0.4, 0)\n",
    "    return overlay\n",
    "\n",
    "def display_results(images, cams):\n",
    "    \"\"\"Display original images and XGrad-CAM heatmaps side by side.\"\"\"\n",
    "    fig, axes = plt.subplots(len(images), 2, figsize=(10, 5 * len(images)))\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (image, cam) in enumerate(zip(images, cams)):\n",
    "        overlay = overlay_heatmap(image, cam)\n",
    "        \n",
    "        axes[i][0].imshow(np.transpose(image.numpy(), (1, 2, 0)))\n",
    "        axes[i][0].set_title(\"Original Image\")\n",
    "        axes[i][0].axis(\"off\")\n",
    "        \n",
    "        axes[i][1].imshow(overlay)\n",
    "        axes[i][1].set_title(\"XGrad-CAM Heatmap\")\n",
    "        axes[i][1].axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a batch of sample images\n",
    "    images = torch.randn(4, 3, 224, 224)  # Simulated batch with 4 images\n",
    "    cams = apply_xgrad_cam(model, images)\n",
    "    \n",
    "    # Display results for all images\n",
    "    display_results(images, cams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Xception Model (same as LIME notebook)\n",
    "from training.detectors import DETECTOR\n",
    "import yaml\n",
    "\n",
    "def load_config(path, additional_args={}):\n",
    "    with open(path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "path = \"./training/config/detector/xception.yaml\"\n",
    "additional_args = {'test_batchSize': 12, 'pretrained': './weights/ckpt_best.pth'}\n",
    "config = load_config(path, additional_args=additional_args)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "model.eval()\n",
    "\n",
    "# Select the last convolutional layer\n",
    "TARGET_LAYER = model.backbone.features[-1]  # Adjust if needed\n",
    "\n",
    "# Define function to apply XGrad-CAM\n",
    "def apply_xgrad_cam(model, images, target_class=1):\n",
    "    cam = XGradCAM(model=model, target_layers=[TARGET_LAYER])\n",
    "    targets = [ClassifierOutputTarget(target_class)]\n",
    "    grayscale_cam = cam(input_tensor=images, targets=targets)  # Generate CAM\n",
    "    grayscale_cam = grayscale_cam[0, :]  # Extract CAM for first batch\n",
    "    return grayscale_cam\n",
    "\n",
    "# Function to overlay heatmap\n",
    "def overlay_heatmap(image, cam):\n",
    "    image = np.transpose(image.numpy(), (1, 2, 0))  # Convert from Tensor format\n",
    "    image = (image - image.min()) / (image.max() - image.min())  # Normalize\n",
    "    cam = cv2.resize(cam, (224, 224))  # Resize CAM to match image size\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    overlay = (heatmap / 255) * 0.5 + image\n",
    "    overlay = (overlay - overlay.min()) / (overlay.max() - overlay.min())\n",
    "    return overlay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
